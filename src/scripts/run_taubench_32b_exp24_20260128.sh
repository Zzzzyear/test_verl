#!/bin/bash
set -e
ulimit -n 1048576

export NCCL_IB_TIMEOUT=22
export NCCL_IB_TC=160
export NCCL_NET_GDR_LEVEL=2
export NCCL_ALGO=Ring
export NCCL_DEBUG=INFO
export NCCL_SOCKET_IFNAME=eth0
export NCCL_IB_DISABLE=0
export NCCL_P2P_DISABLE=0

# ================= 1. ç”¨æˆ·é…ç½®åŒº (åœ¨æ­¤ä¿®æ”¹) =================

# [ä»»åŠ¡] mixed | math | code | dryrun | open-r1-math-pmtlth1024
# ä½ åœ¨ egpo_train_config.yaml æ–°å¢žçš„ taskï¼š
TASK="open-r1-math-pmtlth1024"

# [æ¨¡å¼] debug | debug_10g | 4gpu | 8gpu | limit_35g
MODE="4gpu"

# [æ˜¾å¡] æŒ‡å®š GPU ID (é€—å·åˆ†éš”), å¦‚ "0" æˆ– "0,1,2,3"
GPU_IDS="0,1,2,3"
nnodes=1

# # [æ¨¡åž‹] ç›¸å¯¹è·¯å¾„ (ç›¸å¯¹äºŽ ROOT_CANDIDATES)
# MODEL_REL_PATH="models/Qwen/Qwen3-1.7B"

# [Qwen3 thinking ä¸€é”®å¼€å…³] auto | on | off
# - auto(é»˜è®¤): ä»…å½“æ¨¡åž‹æ˜¯ Qwen3 æ—¶ -> enable_thinking=Trueï¼›å…¶å®ƒæ¨¡åž‹ä¸æ³¨å…¥ï¼ˆå®Œå…¨ä¸å½±å“ï¼‰
# - on        : å¯¹ Qwen3 å¼ºåˆ¶ enable_thinking=Trueï¼ˆéž Qwen3 ä¹Ÿä¸ä¼šæ³¨å…¥ï¼Œé¿å…å½±å“ï¼‰
# - off       : å¯¹ Qwen3 å¼ºåˆ¶ enable_thinking=Falseï¼ˆéž Qwen3 ä¹Ÿä¸ä¼šæ³¨å…¥ï¼Œé¿å…å½±å“ï¼‰
THINKING_MODE="${THINKING_MODE:-auto}"

# [Reward Manager]
# - é»˜è®¤ç”¨ hybridï¼šå¯ç›´æŽ¥è·‘é€šä½ å½“å‰ openr1_math æ•°æ®ï¼ˆå› ä¸º hybrid è‡ªå·±å®žçŽ°äº† math åˆ¤åˆ†ï¼‰
REWARD_MANAGER="${REWARD_MANAGER:-hybrid}"   # hybrid | dapo

# [DAPO æ ¸å¿ƒè¶…å‚]
CLIP_RATIO_LOW="${CLIP_RATIO_LOW:-0.2}"
CLIP_RATIO_HIGH="${CLIP_RATIO_HIGH:-0.28}"

# åŠ¨æ€é‡‡æ ·è¿‡æ»¤ï¼ˆDAPO çš„å…³é”®ï¼‰
FILTER_GROUPS_ENABLE="${FILTER_GROUPS_ENABLE:-True}"
FILTER_GROUPS_METRIC="${FILTER_GROUPS_METRIC:-seq_reward}"   # æŽ¨è seq_rewardï¼›ä¹Ÿå¯ acc/scoreï¼ˆä½†è¦æ±‚ reward_extra_info é‡Œæœ‰ï¼‰
MAX_NUM_GEN_BATCHES="${MAX_NUM_GEN_BATCHES:-10}"

# Overlong bufferï¼ˆä»…å½“ REWARD_MANAGER=dapo æ—¶çœŸæ­£ç”Ÿæ•ˆï¼‰
OVERLONG_ENABLE="${OVERLONG_ENABLE:-False}"
OVERLONG_LEN="${OVERLONG_LEN:-128}"
OVERLONG_PENALTY="${OVERLONG_PENALTY:-1.0}"
# ==========================================================

# --- 2. æ™ºèƒ½è·¯å¾„æŽ¢æµ‹---
# echo "ðŸ” Detecting Model Path..."

# ROOT_CANDIDATES=(
#     "/data-store/zhaoqiannian"  # è®­ç»ƒæœåŠ¡å™¨
#     "/data/zhaoqn"              # æµ‹è¯•æœåŠ¡å™¨
# )

# DETECTED_ROOT=""
# for root in "${ROOT_CANDIDATES[@]}"; do
#     if [ -d "$root" ]; then
#         DETECTED_ROOT="$root"
#         break
#     fi
# done

# if [ -z "$DETECTED_ROOT" ]; then
#     echo "   âŒ Error: Could not find any known user directories!"
#     exit 1
# fi

# MODEL_PATH="$DETECTED_ROOT/$MODEL_REL_PATH"

# if [ ! -d "$MODEL_PATH" ]; then
#     echo "   âŒ Error: Model not found at expected path: $MODEL_PATH"
#     echo "      Please check 'MODEL_REL_PATH' configuration."
#     exit 1
# fi
# echo "   âœ… Target Model: $MODEL_PATH"

MODEL_PATH="/opt/nas/p/achen/open_models/Qwen_Qwen2.5-Math-1.5B"
MODEL_NAME="Qwen_Qwen2.5-Math-1.5B"

# --- 3. æ¨¡å¼é€‰æ‹©ç­–ç•¥ ---
if [ -n "$MODE" ]; then
    echo "   ðŸ‘‰ Using User-Specified Mode: $MODE"
else
    if [[ "$DETECTED_ROOT" == *"/data/zhaoqn"* ]]; then
        MODE="debug_10g"
        echo "   ðŸ›¡ï¸  Safety Policy: Test Server detected. Auto-setting MODE='debug_10g'."
    else
        MODE="debug"
        echo "   ðŸ’¡ Safety Policy: Training Server detected. Auto-setting MODE='debug'."
    fi
fi


# --- 4. åŸºç¡€çŽ¯å¢ƒå‡†å¤‡ ---
PROJECT_ROOT="$(cd "$(dirname "$0")/../../" && pwd)"
CONFIG_FILE="$PROJECT_ROOT/src/config/egpo_train_config_exp24_20260128.yaml"
UTILS_SCRIPT="$PROJECT_ROOT/src/scripts/utils/generate_cmd.py"

# å¼ºåˆ¶æ·»åŠ  verl æºç ç›®å½•åˆ° PYTHONPATH
export PYTHONPATH="${PROJECT_ROOT}/verl:$PYTHONPATH"

# vLLM & PyTorch æ€§èƒ½çŽ¯å¢ƒå˜é‡
export VLLM_USE_V1=1
export VLLM_NO_USAGE_STATS=1  # ç¦æ­¢ vLLM ä¸ŠæŠ¥ç»Ÿè®¡ï¼ŒåŠ å¿«å¯åŠ¨
export RAY_DEDUP_LOGS=0       # ç¦æ­¢ Ray æŠ˜å é‡å¤æ—¥å¿—ï¼Œä¾¿äºŽè°ƒè¯•
unset PYTORCH_CUDA_ALLOC_CONF
export PYTORCH_CUDA_ALLOC_CONF="max_split_size_mb:512"

# å…³é”®å…œåº•ï¼šé¿å… vLLM æ”¾è¡Œè¶…é•¿ max_model_len
unset VLLM_ALLOW_LONG_MAX_MODEL_LEN
export CUDA_VISIBLE_DEVICES="$GPU_IDS"
NUM_VISIBLE_GPUS=$(echo "$GPU_IDS" | tr ',' '\n' | wc -l)


# --- 5. å‚æ•°ç”Ÿæˆä¸Žæ£€æŸ¥ ---
# TIMESTAMP=$(TZ='Asia/Shanghai' date +%m%d_%H%M)
ADV_ESTIMATOR="dapo"
TIMESTAMP=$(date -d "UTC +8 hours" +%m%d_%H%M)
EXP_NAME="${TASK}_${MODEL_NAME}_${MODE}_${ADV_ESTIMATOR}_${TIMESTAMP}"
LOG_DIR="$PROJECT_ROOT/outputs/logs/$EXP_NAME"
mkdir -p "$LOG_DIR"

echo "========================================================"
echo "ðŸš€ DAPO Launcher (RayDAPOTrainer)"
echo "========================================================"
echo "   Task        : $TASK"
echo "   Mode        : $MODE"
echo "   GPUs        : $GPU_IDS (Count: $NUM_VISIBLE_GPUS)"
echo "   RewardMgr    : $REWARD_MANAGER"
echo "   Adv Estimator: grpo (DAPO uses GRPO advantage + sampling/clip tweaks)"
echo "   Clip         : low=$CLIP_RATIO_LOW high=$CLIP_RATIO_HIGH"
echo "   FilterGroups : enable=$FILTER_GROUPS_ENABLE metric=$FILTER_GROUPS_METRIC max_gen_batches=$MAX_NUM_GEN_BATCHES"
echo "   Config      : $CONFIG_FILE"
echo "   PROJECT_ROOT: $PROJECT_ROOT"
echo "   EXP_NAME    : $EXP_NAME"
echo "   Thinking    : $THINKING_MODE"
echo "========================================================"

CMD_ARGS=$(python3 "$UTILS_SCRIPT" \
    --config "$CONFIG_FILE" \
    --task "$TASK" \
    --mode "$MODE" \
    --project_root "$PROJECT_ROOT" \
    --exp_name "$EXP_NAME" \
    --model_path "$MODEL_PATH" \
    --nnodes "$nnodes")


# --- 5.1 Qwen3 thinking å¼€å…³ï¼ˆæœ€å°æ”¹åŠ¨ï¼šåªåœ¨ CMD_ARGS æœ«å°¾è¿½åŠ  overrideï¼‰ ---
IS_QWEN3=0
if [[ "$MODEL_PATH" == *"Qwen3"* || "$MODEL_REL_PATH" == *"Qwen3"* ]]; then
  IS_QWEN3=1
fi

ENABLE_THINKING_OVERRIDE=""

case "$THINKING_MODE" in
  auto)
    if [ "$IS_QWEN3" -eq 1 ]; then
      # ç”¨ ++ æ›´ç¨³ï¼šæœªæ¥å¦‚æžœ yaml é‡Œé¢„å…ˆå®šä¹‰äº† enable_thinkingï¼Œä¹Ÿä¸ä¼šæŠ¥ â€œkey already existsâ€
      ENABLE_THINKING_OVERRIDE="++data.apply_chat_template_kwargs.enable_thinking=True"
    fi
    ;;
  on|1|true|True)
    if [ "$IS_QWEN3" -eq 1 ]; then
      ENABLE_THINKING_OVERRIDE="++data.apply_chat_template_kwargs.enable_thinking=True"
    fi
    ;;
  off|0|false|False)
    if [ "$IS_QWEN3" -eq 1 ]; then
      ENABLE_THINKING_OVERRIDE="++data.apply_chat_template_kwargs.enable_thinking=False"
    fi
    ;;
  *)
    echo "âŒ ERROR: THINKING_MODE must be auto|on|off (got '$THINKING_MODE')"
    exit 1
    ;;
esac

if [ -n "$ENABLE_THINKING_OVERRIDE" ]; then
  CMD_ARGS="$CMD_ARGS $ENABLE_THINKING_OVERRIDE"
  echo "   ðŸ§  apply_chat_template.enable_thinking -> $ENABLE_THINKING_OVERRIDE"
else
  if [ "$IS_QWEN3" -eq 1 ]; then
    echo "   ðŸ§  apply_chat_template.enable_thinking -> (no override)"
  else
    echo "   ðŸ§  non-Qwen3 model detected; thinking override skipped (won't affect other models)"
  fi
fi


# --- 5.2 è®¡ç®—ä¸€ä¸ªæ›´åˆé€‚çš„ gen_batch_sizeï¼ˆé»˜è®¤ = train_batch_size * 4ï¼‰ ---
TRAIN_BSZ=$(echo "$CMD_ARGS" | grep -o "data.train_batch_size=[0-9]*" | cut -d= -f2)
if [ -z "$TRAIN_BSZ" ]; then
  echo "âŒ ERROR: failed to parse data.train_batch_size from CMD_ARGS"
  exit 1
fi
GEN_BSZ=$((TRAIN_BSZ * 4))


REQUIRED_GPUS=$(echo "$CMD_ARGS" | grep -o "trainer.n_gpus_per_node=[0-9]*" | cut -d= -f2)
if [ "$NUM_VISIBLE_GPUS" -lt "$REQUIRED_GPUS" ]; then
    echo "âŒ ERROR: Mode '$MODE' requires $REQUIRED_GPUS GPUs, but you provided $NUM_VISIBLE_GPUS ($GPU_IDS)."
    exit 1
fi


# --- 6. DAPO ä¸“å±ž overridesï¼ˆè¦†ç›– generate_cmd çš„é»˜è®¤å€¼ï¼‰ ---
# å…³é”®ç‚¹ï¼š
# - æ¢å…¥å£ï¼šrecipe.dapo.main_dapo ï¼ˆå†…éƒ¨ç”¨ RayDAPOTrainerï¼‰
# - adv_estimator=grpoï¼ˆDAPO ä¸æ˜¯æ–° advantage estimatorï¼‰
# - asymmetric clip
# - filter_groups åŠ¨æ€é‡‡æ ·ï¼ˆDAPO æœ€å…³é”®ï¼‰
# - reward_manager å¯é€‰ï¼šhybrid(å…ˆè·‘é€š) æˆ– dapo(ä¸¥æ ¼å¤çŽ° + overlong)

DAPO_OVERRIDES="
algorithm.adv_estimator=grpo
reward_model.reward_manager=${REWARD_MANAGER}
data.gen_batch_size=${GEN_BSZ}
actor_rollout_ref.actor.clip_ratio_low=${CLIP_RATIO_LOW}
actor_rollout_ref.actor.clip_ratio_high=${CLIP_RATIO_HIGH}
algorithm.filter_groups.enable=${FILTER_GROUPS_ENABLE}
algorithm.filter_groups.metric=${FILTER_GROUPS_METRIC}
algorithm.filter_groups.max_num_gen_batches=${MAX_NUM_GEN_BATCHES}
actor_rollout_ref.actor.use_kl_loss=False
algorithm.use_kl_in_reward=False
reward_model.overlong_buffer.enable=${OVERLONG_ENABLE}
reward_model.overlong_buffer.len=${OVERLONG_LEN}
reward_model.overlong_buffer.penalty_factor=${OVERLONG_PENALTY}
"

# æ¸…ç†æˆä¸€è¡Œ
DAPO_OVERRIDES=$(echo "$DAPO_OVERRIDES" | tr '\n' ' ' | xargs)

# --- 7. å¯åŠ¨è®­ç»ƒ ---
export HYDRA_FULL_ERROR=1
export WANDB_API_KEY=e5eabf51ce79203f59fe61312c26901ca0e24d1a
export WANDB_PROJECT="EGPO_Unified"
export WANDB_ENTITY="egpo-paper"
export WANDB_NAME="$EXP_NAME"
export WANDB_DIR="$LOG_DIR"
export WANDB_MODE="online"

# è®°å½•æœ€ç»ˆæ‰§è¡Œå‘½ä»¤
echo "python3 -u -m recipe.dapo.main_dapo $CMD_ARGS $DAPO_OVERRIDES" | tee "$LOG_DIR/launch_cmd.txt"

echo "   > Executing Training..."
python3 -u -m recipe.dapo.main_dapo $CMD_ARGS $DAPO_OVERRIDES 2>&1 | tee "$LOG_DIR/train.log"

