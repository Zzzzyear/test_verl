#!/bin/bash
# è·¯å¾„ï¼š/data-store/zhaoqiannian/workspace/EGPO/src/scripts/run_entropy_flexible.sh

# ================= 1. è¾“å…¥å‚æ•°è§£æ =================
if [ -z "$1" ]; then
    echo "Usage: $0 <GPU_IDS_COMMA_SEPARATED>"
    echo "Examples:"
    echo "  Single Card:  bash $0 1"
    echo "  Two Cards:    bash $0 0,1"
    echo "  Three Cards:  bash $0 0,1,2"
    exit 1
fi

# è§£æ GPU åˆ—è¡¨
GPU_STRING=$1
IFS=',' read -r -a GPU_ARRAY <<< "$GPU_STRING"
NUM_GPUS=${#GPU_ARRAY[@]}

echo "========================================================"
echo "   ğŸš€ EGPO Entropy Analysis Launcher"
echo "   Detected GPUs: ${GPU_ARRAY[*]} (Total: $NUM_GPUS)"
echo "========================================================"

# ================= 2. ç¯å¢ƒä¸è·¯å¾„é…ç½® =================
# é»„é‡‘ç¯å¢ƒé…ç½®
export VLLM_USE_V1=1
unset PYTORCH_CUDA_ALLOC_CONF

# è·¯å¾„å®šä¹‰
BASE_DIR="/data-store/zhaoqiannian"
PROJECT_ROOT="$BASE_DIR/workspace/EGPO"
DATA_PATH="$PROJECT_ROOT/datasets/processed/math_single.parquet"
# æ ¹æ® GPU ç»„åˆåˆ›å»ºç‹¬ç«‹çš„è¾“å‡ºç›®å½•ï¼Œé˜²æ­¢æ··æ·†
OUTPUT_DIR="$PROJECT_ROOT/outputs/analysis/full_experiment_b1_flexible"
SCRIPT_PATH="$PROJECT_ROOT/src/scripts/analyze_entropy.py"

mkdir -p "$OUTPUT_DIR"

# å®éªŒå‚æ•°
SAMPLE_SIZE=800
N_RETURN=8

# ================= 3. å®šä¹‰ä»»åŠ¡å‡½æ•° =================
# å‚æ•°: 1.æ¨¡å‹è·¯å¾„ 2.æ¨¡å‹æ˜¾ç¤ºå 3.æ—¥å¿—æ–‡ä»¶å 4.åˆ†é…çš„GPU_ID
run_task() {
    local m_path=$1
    local m_name=$2
    local log_file=$3
    local gpu_id=$4

    echo ">>> [GPU $gpu_id] Starting $m_name ..."
    
    # æ˜¾å¼æŒ‡å®šå½“å‰å­è¿›ç¨‹å¯è§çš„ GPU
    export CUDA_VISIBLE_DEVICES=$gpu_id
    
    python3 -u $SCRIPT_PATH \
        --model_path "$m_path" \
        --model_name "$m_name" \
        --data_path "$DATA_PATH" \
        --output_dir "$OUTPUT_DIR" \
        --sample_size $SAMPLE_SIZE \
        --n_return $N_RETURN \
        --tp_size 1 \
        > "$OUTPUT_DIR/$log_file" 2>&1

    if [ $? -eq 0 ]; then
        echo "âœ… [GPU $gpu_id] $m_name Finished. Log: $OUTPUT_DIR/$log_file"
    else
        echo "âŒ [GPU $gpu_id] $m_name Failed! Check Log: $OUTPUT_DIR/$log_file"
    fi
}

# ================= 4. åŠ¨æ€è°ƒåº¦é€»è¾‘ =================

# å®šä¹‰æ¨¡å‹ä¿¡æ¯
P_1B="$BASE_DIR/models/Qwen/Qwen3-1.7B"
P_4B="$BASE_DIR/models/Qwen/Qwen3-4B"
P_8B="$BASE_DIR/models/Qwen/Qwen3-8B"

if [ "$NUM_GPUS" -eq 1 ]; then
    # --- å•å¡æ¨¡å¼ (ä¸²è¡Œ) ---
    GPU=${GPU_ARRAY[0]}
    echo "Mode: Serial Execution on GPU $GPU"
    
    run_task "$P_1B" "Qwen3-1.7B" "qwen1.7b.log" $GPU
    run_task "$P_4B" "Qwen3-4B"   "qwen4b.log"   $GPU
    run_task "$P_8B" "Qwen3-8B"   "qwen8b.log"   $GPU

elif [ "$NUM_GPUS" -eq 2 ]; then
    # --- åŒå¡æ¨¡å¼ (å¹¶è¡Œ) ---
    # ç­–ç•¥ï¼šå°æ¨¡å‹(1.7B+4B)å…±ç”¨ä¸€å¼ å¡ä¸²è¡Œï¼Œå¤§æ¨¡å‹(8B)ç‹¬å ä¸€å¼ å¡
    GPU_A=${GPU_ARRAY[0]}
    GPU_B=${GPU_ARRAY[1]}
    echo "Mode: Balanced Parallel Execution (Small models on $GPU_A, Large on $GPU_B)"

    # ä»»åŠ¡ç»„ A (åå°è¿è¡Œ)
    (
        run_task "$P_1B" "Qwen3-1.7B" "qwen1.7b.log" $GPU_A
        run_task "$P_4B" "Qwen3-4B"   "qwen4b.log"   $GPU_A
    ) &

    # ä»»åŠ¡ç»„ B (åå°è¿è¡Œ)
    (
        run_task "$P_8B" "Qwen3-8B"   "qwen8b.log"   $GPU_B
    ) &

    wait # ç­‰å¾…ä¸¤ç»„éƒ½å®Œæˆ

else
    # --- ä¸‰å¡åŠä»¥ä¸Šæ¨¡å¼ (å…¨å¹¶è¡Œ) ---
    echo "Mode: Full Parallel Execution"
    
    GPU_A=${GPU_ARRAY[0]}
    GPU_B=${GPU_ARRAY[1]}
    GPU_C=${GPU_ARRAY[2]}

    ( run_task "$P_1B" "Qwen3-1.7B" "qwen1.7b.log" $GPU_A ) &
    ( run_task "$P_4B" "Qwen3-4B"   "qwen4b.log"   $GPU_B ) &
    ( run_task "$P_8B" "Qwen3-8B"   "qwen8b.log"   $GPU_C ) &

    wait
fi

echo "========================================================"
echo "ğŸ‰ All Analysis Tasks Completed."
echo "========================================================"

# GPU 1 nohup bash src/scripts/run_entropy_flexible.sh 1 > outputs/logs/run_entropy.log 2>&1 &
# GPU 1,2 nohup bash src/scripts/run_entropy_flexible.sh 1,2 > outputs/logs/run_entropy.log 2>&1 &
# GPU 0,1,3 nohup bash src/scripts/run_entropy_flexible.sh 0,1,3 > outputs/logs/run_entropy.log 2>&1 &