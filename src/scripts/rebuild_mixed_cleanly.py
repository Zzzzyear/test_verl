import os
import glob
import pandas as pd
import numpy as np
import json
from datasets import Dataset, load_dataset
from tqdm import tqdm

# ================= é…ç½® =================
BASE_DIR = "/data/zhaoqn/workspace/EGPO/datasets/processed"
RAW_DIR = "/data/zhaoqn/workspace/EGPO/datasets/raw"
OUTPUT_FILE = os.path.join(BASE_DIR, "mixed_reasoning.parquet")

TARGET_COUNTS = {
    "math": 24000,
    "code": 24000,
    "science": 12000
}

def clean_record(record):
    """
    æ¸…æ´—å•æ¡æ•°æ®ï¼Œç¡®ä¿æ˜¯çº¯å‡€çš„ Python å¯¹è±¡ã€‚
    """
    try:
        # æ¸…æ´— messages åˆ—è¡¨
        def fix_msgs(msgs):
            # 1. è§£åŒ… numpy/arrow å®¹å™¨
            if isinstance(msgs, np.ndarray): msgs = msgs.tolist()
            if not isinstance(msgs, list): return []
            
            cleaned = []
            for m in msgs:
                # 2. å¼ºåˆ¶å°†å†…å®¹è½¬ä¸ºå­—ç¬¦ä¸² (é˜²æ­¢ None æŠ¥é”™)
                role = str(m.get('role', ''))
                content = str(m.get('content', ''))
                cleaned.append({"role": role, "content": content})
            return cleaned

        return {
            "data_source": str(record['data_source']),
            "ability": str(record['ability']),
            "prompt": fix_msgs(record['prompt']),
            "response": fix_msgs(record['response']),
            # [Fix 1] å¿…é¡»é€ä¼  ground_truthï¼
            "ground_truth": str(record.get('ground_truth', '')) 
        }
    except Exception as e:
        return None

def get_science_data():
    print("ðŸ”¹ Extracting Science from Mixture-of-Thoughts...")
    files = glob.glob(os.path.join(RAW_DIR, "Mixture-of-Thoughts", "**/*.parquet"))
    # ä½¿ç”¨ HF åŠ è½½ä»¥ä¿æŒä¸€è‡´æ€§
    ds = load_dataset("parquet", data_files=files, split="train")
    
    # è¿‡æ»¤å‡º Science
    ds_sci = ds.filter(
        lambda x: 'math' not in str(x['source']).lower() and 'code' not in str(x['source']).lower(),
        num_proc=16
    )
    
    science_list = []
    for row in tqdm(ds_sci, desc="Formatting Science"):
        msgs = row['messages']
        if isinstance(msgs, np.ndarray): msgs = msgs.tolist()
        
        u, a = "", ""
        for m in msgs:
            if m['role'] == 'user': u = m['content']
            if m['role'] == 'assistant': a = m['content']
            
        if u and a:
            science_list.append({
                "data_source": "mixture",
                "ability": "science",
                "prompt": [{"role": "user", "content": u}],
                "response": [{"role": "assistant", "content": a}],
                # [Fix 2] æ–°å¢ž ground_truthï¼ŒScience é¢˜çš„ GT é€šå¸¸å°±æ˜¯ assistant çš„å®Œæ•´å›žå¤
                "ground_truth": a 
            })
            
    # é‡‡æ ·
    import random
    if len(science_list) > TARGET_COUNTS['science']:
        random.shuffle(science_list)
        science_list = science_list[:TARGET_COUNTS['science']]
        
    return science_list

def main():
    print("ðŸš€ Starting Pandas-Bridge Rebuild (Robust Mode)...")
    
    # 1. åŠ è½½å·²éªŒè¯çš„ Math/Code æ•°æ®
    print("--> Loading Math Single...")
    df_math = pd.read_parquet(os.path.join(BASE_DIR, "math_single.parquet"))
    # ç¡®ä¿ math_single å·²ç»ç”± prep_dataset.py ç”Ÿæˆäº† ground_truthï¼Œå¦åˆ™è¿™é‡Œä¼šæŠ¥é”™æˆ–ä¸¢æ•°æ®
    if 'ground_truth' not in df_math.columns:
        print("âš ï¸ Warning: 'ground_truth' missing in math_single.parquet! Please run prep_dataset.py first.")
        
    math_data = df_math.to_dict('records')
    if len(math_data) > TARGET_COUNTS['math']:
        import random
        random.shuffle(math_data)
        math_data = math_data[:TARGET_COUNTS['math']]

    print("--> Loading Code Single...")
    df_code = pd.read_parquet(os.path.join(BASE_DIR, "code_single.parquet"))
    code_data = df_code.to_dict('records')
    if len(code_data) > TARGET_COUNTS['code']:
        import random
        random.shuffle(code_data)
        code_data = code_data[:TARGET_COUNTS['code']]

    # 2. æå– Science
    science_data = get_science_data()
    print(f"    Science Count: {len(science_data)}")

    # 3. åˆå¹¶ä¸Žæ·±åº¦æ¸…æ´—
    print("--> Merging & Deep Cleaning...")
    raw_list = math_data + code_data + science_data
    import random
    random.shuffle(raw_list)
    
    cleaned_list = []
    for r in tqdm(raw_list, desc="Sanitizing"):
        c = clean_record(r)
        if c: cleaned_list.append(c)

    # 4. ä½¿ç”¨ Pandas ä½œä¸ºä¸­é—´æ¡¥æ¢
    print("--> Converting to Pandas DataFrame...")
    df_final = pd.DataFrame(cleaned_list)
    
    print("--> Converting to HuggingFace Dataset...")
    # Dataset.from_pandas ä¼šè‡ªåŠ¨æŽ¨æ–­æœ€å®Œç¾Žçš„ Schema
    hf_dataset = Dataset.from_pandas(df_final)
    
    # 5. ä¿å­˜
    print(f"--> Saving to {OUTPUT_FILE}...")
    hf_dataset.to_parquet(OUTPUT_FILE)
    
    print("\nâœ… DONE! Mixed Dataset Rebuilt Successfully.")
    print(f"   Total: {len(hf_dataset)}")
    print("   Now run check_data.py one last time.")

if __name__ == "__main__":
    main()