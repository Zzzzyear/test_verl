import os
import json
import numpy as np
from datasets import load_dataset
from termcolor import colored  # å¦‚æœæ²¡æœ‰å®‰è£…ï¼Œè„šæœ¬ä¼šè‡ªåŠ¨é™çº§å¤„ç†

# ================= é…ç½®åŒº =================
BASE_DIR = "/data/zhaoqn/workspace/EGPO"
DATA_DIR = os.path.join(BASE_DIR, "datasets/processed")

EXPECTED_FILES = {
    "openr1_pool_train": "math_openr1_pool30k_random_source_softcap_train_final.parquet",
    "openr1_pool_val":   "math_openr1_pool30k_random_source_softcap_val_fixed.parquet"
}

# ================= è¾…åŠ©å·¥å…· =================
def print_status(msg, status):
    """æ‰“å°å¸¦é¢œè‰²çš„çŠ¶æ€ä¿¡æ¯"""
    try:
        if status == "PASS":
            print(f"   [{colored('PASS', 'green')}] {msg}")
        elif status == "FAIL":
            print(f"   [{colored('FAIL', 'red')}] {msg}")
        elif status == "WARN":
            print(f"   [{colored('WARN', 'yellow')}] {msg}")
        else:
            print(f"   [{status}] {msg}")
    except ImportError:
        # å¦‚æœæ²¡æœ‰ termcolorï¼Œä½¿ç”¨æ™®é€šæ‰“å°
        symbol = "âœ…" if status == "PASS" else "âŒ" if status == "FAIL" else "âš ï¸"
        print(f"   [{symbol} {status}] {msg}")

def validate_dataset(name, filename):
    filepath = os.path.join(DATA_DIR, filename)
    print(f"\nğŸ” Inspecting Dataset: {name} ({filename})")
    print("-" * 60)

    if not os.path.exists(filepath):
        print_status(f"File not found: {filepath}", "FAIL")
        return False

    try:
        # 1. æ¨¡æ‹Ÿè®­ç»ƒå™¨åŠ è½½ (ä½¿ç”¨ datasets åº“ï¼Œè€Œé pandas)
        # è¿™æ˜¯åˆ¤æ–­èƒ½å¦è·‘é€šè®­ç»ƒçš„å”¯ä¸€æ ‡å‡†
        ds = load_dataset("parquet", data_files=filepath, split="train")
        print_status(f"Successfully loaded {len(ds)} samples", "PASS")
        
        # 2. ç±»å‹å®‰å…¨æ£€æŸ¥ (Type Safety)
        # æ£€æŸ¥ç¬¬ä¸€æ¡æ•°æ®ï¼Œç¡®ä¿æ˜¯ Python List è€Œé Numpy Array
        sample = ds[0]
        prompt = sample['prompt']
        response = sample['response']
        
        if isinstance(prompt, list) and isinstance(response, list):
            print_status("Data types are pure Python List (Trainer Compatible)", "PASS")
        elif isinstance(prompt, np.ndarray) or isinstance(response, np.ndarray):
            print_status(f"Detected Numpy Array! (Prompt: {type(prompt)})", "FAIL")
            return False
        else:
            print_status(f"Unknown type detected: {type(prompt)}", "WARN")

        # 3. ç»“æ„æ£€æŸ¥ (Structure)
        # ç¡®ä¿ List é‡Œé¢åŒ…çš„æ˜¯ Dict
        if len(prompt) > 0 and isinstance(prompt[0], dict) and 'role' in prompt[0]:
            print_status("Chat template structure (List[Dict]) is correct", "PASS")
        else:
            print_status("Invalid Chat structure", "FAIL")
            return False

        # 4. å†…å®¹å®Œæ•´æ€§ (Content Integrity)
        # æ£€æŸ¥ Ground Truth æ˜¯å¦æœ‰æ•ˆ
        error_count = 0
        empty_gt_count = 0
        
        # å®šä¹‰æ£€æŸ¥å‡½æ•°
        def check_row(ex):
            nonlocal error_count, empty_gt_count
            gt = ex['reward_model']['ground_truth']
            ability = ex['ability']
            
            # æ£€æŸ¥ç©ºå€¼
            if not gt or len(str(gt).strip()) == 0:
                empty_gt_count += 1
                return
            
            # Code ä»»åŠ¡å¿…é¡»æ˜¯åˆæ³• JSON
            if ability == 'code':
                try:
                    json.loads(gt)
                except:
                    error_count += 1

        # æŠ½æ ·æ£€æŸ¥ 1000 æ¡ (å…¨é‡æ£€æŸ¥å¤ªæ…¢ï¼ŒæŠ½æ ·è¶³å¤Ÿä»£è¡¨æ€§)
        check_size = min(1000, len(ds))
        ds.select(range(check_size)).map(check_row, load_from_cache_file=False)
        
        if error_count > 0:
            print_status(f"Found {error_count} invalid Code GTs (JSON parse fail)", "FAIL")
            return False
        else:
            print_status("Code GT JSON validity check passed", "PASS")

        if empty_gt_count > 0:
            # ç©º GT åªæ˜¯è­¦å‘Šï¼Œä¸å½±å“è·‘é€šï¼Œåªè¦æ•°é‡ä¸å¤š
            print_status(f"Found {empty_gt_count} empty Ground Truths (Acceptable noise)", "WARN")
        else:
            print_status("No empty Ground Truths found", "PASS")

        return True

    except Exception as e:
        print_status(f"Critical Load Error: {str(e)}", "FAIL")
        return False

# ================= ä¸»ç¨‹åº =================

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸš€ EGPO FINAL DATASET VALIDATION")
    print("=" * 60)
    print(f"Target Directory: {DATA_DIR}")
    
    all_passed = True
    results = {}

    for name, fname in EXPECTED_FILES.items():
        is_valid = validate_dataset(name, fname)
        results[name] = is_valid
        if not is_valid:
            all_passed = False

    print("\n" + "=" * 60)
    print("ğŸ“Š VALIDATION SUMMARY")
    print("=" * 60)
    
    for name, passed in results.items():
        status = "âœ… READY" if passed else "âŒ FAILED"
        print(f"{name:<10} : {status}")

    print("-" * 60)
    if all_passed:
        print("\nğŸ‰ ALL SYSTEMS GO! Dataset is strictly validated and ready for training.")
        print("   Run the following command to start training:")
        print(f"\n   bash src/scripts/run_egpo.sh")
    else:
        print("\nâ›” BLOCKER: Please fix the failed datasets before training.")